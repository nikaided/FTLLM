- 「ファインチューニングLLMクラブ」という名称はかっこ悪いため、以後は「FTLLMクラブ」と略記することにする。

# 目次
0. プログラムの実行環境について
1. FTLLMクラブの趣旨と運営方針
2. FTLLMクラブの参加要件
3. FTLLMクラブ開催の経緯と趣旨
4. 主催者の野望：自然言語処理×強化学習(RLHF)


# プログラムの実行環境について
当レポジトリのプログラムは.ipynbファイルに記述されています。勉強会ではkaggleのカーネル上で実行する予定ですが、ローカルで実行する場合は以下の手順をふんでください。なおGPUがないとつらいことも多いです。

```shell
cd FTLLM_CLUB
python -m venv .env
source .env/Scripts/activate # 各自のデバイスで仮想環境起動
pip -r requirements.txt
```

# FTLLMクラブの趣旨と運営方針
- 参加者がクオリティの高いLLMアプリケーションを開発できるようにコミュニティを形成するのがFTLLMクラブの趣旨です。
- FTLLMクラブはオフライン集会です(つまり参加者は実際にひとつの場所に集まります)
- 2週間に1回の頻度での開催を目論んでいます。
- 参加費は500円です。
- 参加者は各自でPCを持参していただきます。
- 最初の10分の間に主催者が自然言語分野や強化学習分野についてのプレゼンをおこないます。(プレゼンテーションの資料はのちほど添付しておきます)
- 主催者のプレゼンが終わると参加者はひとりで各々の作業をおこなうことができます(AES方式のWi-fiでインターネットへの接続が可能です)
- 参加者は主催者にいつでも質問することができます。質問内容は技術に関するものでも、漠然とした相談のようなもの構いません。主催者はそれらの質問に対していつも真摯に回答することが求められます。

# FTLLMクラブの参加要件
参加要件は以下のとおりです。

- プログラマー

# FTLLMクラブ開催の経緯と趣旨
今年に入ってからchatGPTをはじめとするLLM(大規模言語モデル)を土台にしたアプリケーションサービスが次々とリリースされ、個人的に度肝を抜かれました。これまでも自然言語処理技術を用いたアプリケーションは数多くリリースされてきましたが、そのどれもが物足りない印象でした。たとえば言語翻訳タスクにおいては、google翻訳が長い間第一線でがんばっていましたが、それでも英語ができる人にとってはほとんど使い道はありませんでした。Alexa, siriなどの音声対話型AIもパッとしない印象が顕著で、Amazonやappleのような大企業が巨額の資金を投入しても、満足のいくようなクオリティには達しませんでした。それがDeepLの登場で潮流が変わり始め、chatGPTの登場で一気に変わった。LLMというのはこれまでのアプリケーションとは異なり、個別のタスクだけをこなすものではありません。翻訳や対話のみならず、テキストのセンチメント分類、テキストの要約など、様々なタスクを非常に高い精度でこなす、汎用システムなのです。

LLMと一言で言ってもたくさんのモデルがあります。オープンソースのものもあればAPIだけが公開されているものもあります。英語で事前学習されたものも日本語で学習されたものもあります。毎月新しいモデルが公開され、それらのモデルをファインチューニングしたアプリケーションがリリースされています。またこれらLLMの公開と並行して、hugging faceのようなLLMハブの役割を持ったプラットフォームが興り、LangChainのような周辺機能を扱うようなライブラリも活発に開発されています。ＳＮＳでは毎日のようにLLMに関するTIPSが流れてきますが、情報量が多すぎてまるでついていけません。「アプリケーション開発のために本当に有益な情報は何なのか」という観点で情報をうまく整理し、実際のコードを手になじませることが重要なのかなと思いました。そういったことはひとりでやるには退屈なので勉強会の形をとることにしました。

それがFTLLMクラブ開催の経緯です。



# 主宰者個人の野望
主催者個人の方向性についても簡単に記しておきます。

- 機械学習エンジニア
- オープンエンドな(特定の質疑応答に特化したものではなく、幅広く様々な会話をおこなうような)チャットボットに興味があって今年の4月から勉強を始めました。
- 勉強をしていく中で、同じような目線、環境のひとたちと情報を共有したいが、大阪でそういうコミュニティを見つけるのは困難だと感じていた。
- ファインチューニングの手法として、教師あり学習や、自己教師あり学習ではなく、報酬最大化をベースとした強化学習に興味がある
- 以下の2つの論文を自分なりにアレンジして実装することを夏の目標としている
    - [Fine-Tuning Language Models from Human Preferences](https://arxiv.org/pdf/1909.08593)
    - [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)